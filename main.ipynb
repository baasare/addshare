{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras.backend as K\n",
    "\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import ec\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers.aead import AESGCM\n",
    "\n",
    "from helpers.utils import get_public_key, get_private_key, NumpyEncoder, NumpyDecoder, get_dataset, fetch_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:37:56.879091Z",
     "start_time": "2024-01-12T15:37:56.850524Z"
    }
   },
   "id": "694361724734c663"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def encrypt_message(message, recipient_public_key):\n",
    "    ephemeral_private_key = ec.generate_private_key(ec.SECP256R1(), default_backend())\n",
    "    ephemeral_public_key = ephemeral_private_key.public_key()\n",
    "\n",
    "    shared_secret = ephemeral_private_key.exchange(ec.ECDH(), recipient_public_key)\n",
    "\n",
    "    derived_key_material = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32 + 12,\n",
    "        salt=None,\n",
    "        info=b'',\n",
    "    ).derive(shared_secret)\n",
    "\n",
    "    encryption_key = derived_key_material[:32]\n",
    "    nonce = derived_key_material[32:]\n",
    "\n",
    "    cipher = AESGCM(encryption_key)\n",
    "    ciphertext = cipher.encrypt(nonce, message.encode(), None)\n",
    "\n",
    "    return ephemeral_public_key, ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message(ciphertext, ephemeral_public_key, recipient_private_key):\n",
    "    shared_secret = recipient_private_key.exchange(ec.ECDH(), ephemeral_public_key)\n",
    "\n",
    "    derived_key_material = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32 + 12,\n",
    "        salt=None,\n",
    "        info=b'',\n",
    "    ).derive(shared_secret)\n",
    "\n",
    "    encryption_key = derived_key_material[:32]\n",
    "    nonce = derived_key_material[32:]\n",
    "\n",
    "    cipher = AESGCM(encryption_key)\n",
    "    decrypted_message = cipher.decrypt(nonce, ciphertext, None)\n",
    "\n",
    "    return decrypted_message.decode()\n",
    "\n",
    "# \n",
    "# recipient_private_key = ec.generate_private_key(ec.SECP256R1(), default_backend())\n",
    "# recipient_public_key = recipient_private_key.public_key()\n",
    "# \n",
    "# message_to_encrypt = \"Hello, this is plaintext\"\n",
    "# \n",
    "# ephemeral_public_key, ciphertext = encrypt_message(message_to_encrypt, recipient_public_key)\n",
    "# \n",
    "# print(\"Ciphertext:\", ciphertext)\n",
    "# \n",
    "# decrypted_message = decrypt_message(ciphertext, ephemeral_public_key, recipient_private_key)\n",
    "# print(\"Decrypted Message:\", decrypted_message)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T15:37:58.873997Z",
     "start_time": "2024-01-12T15:37:58.868863Z"
    }
   },
   "id": "46b937130a47da21"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 71ms/step - loss: 1.1147 - accuracy: 0.6400\n"
     ]
    }
   ],
   "source": [
    "indexes = fetch_index(\"mnist\")\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, y_train, x_test, y_test = get_dataset(indexes[0], \"mnist\", x_train, y_train, x_test, y_test)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu', padding='same'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1, batch_size=100, verbose=True)  #  history.history['loss']\n",
    "loss_perturbed = model.evaluate(x_test, y_test, verbose=0)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-12T18:08:39.861512Z",
     "start_time": "2024-01-12T18:08:35.409848Z"
    }
   },
   "id": "1d2aa128291fa20e"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "json_str = json.dumps(model.get_weights(), cls=NumpyEncoder)\n",
    "\n",
    "private_key = get_private_key(1, 'elliptical')\n",
    "public_key = get_public_key(1, 'elliptical')\n",
    "\n",
    "ephemeral_public_key, ciphertext = encrypt_message(json_str, public_key)\n",
    "decrypted_message = decrypt_message(ciphertext, ephemeral_public_key, private_key)\n",
    "decrypted_weights = json.loads(decrypted_message, cls=NumpyDecoder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-12T16:08:17.045869Z"
    }
   },
   "id": "9939794e5f4d26ce"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_logits(model, x):\n",
    "    return model(x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def loss_fn(logits, y):\n",
    "    return K.categorical_crossentropy(y, logits)\n",
    "\n",
    "\n",
    "def random_weight_selection(weights, fraction=0.25):\n",
    "    percentage = max(0, min(100, fraction))\n",
    "    flattened_weights = weights.flatten()\n",
    "    num_elements = int(np.ceil(percentage * flattened_weights.size))\n",
    "    indexes = np.random.choice(flattened_weights.size, size=num_elements, replace=False)\n",
    "    original_indices = np.unravel_index(indexes, weights.shape)\n",
    "    indices = [arr.tolist() for arr in original_indices]\n",
    "    return indices\n",
    "\n",
    "\n",
    "def magnitude_weight_selection(array, percentage=0.25):\n",
    "    percentage = max(0, min(100, percentage))\n",
    "    num_elements = int(np.ceil(percentage / 100 * array.size))\n",
    "    indices_of_largest = np.argpartition(array.flatten(), -num_elements)[-num_elements:]\n",
    "    original_indices = np.unravel_index(indices_of_largest, array.shape)\n",
    "    indices = [arr.tolist() for arr in original_indices]\n",
    "    return indices\n",
    "\n",
    "\n",
    "def obd_weight_selection(model, x, y, weights, fraction):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, weights)\n",
    "        sensitivities = [grad * weight for grad, weight in zip(gradients, weights)]\n",
    "        sensitivities = np.array(sensitivities)\n",
    "        return magnitude_weight_selection(sensitivities, fraction)\n",
    "    \n",
    "def regularization_weight_selection(model, x, y, reg_type, weights, fraction):\n",
    "    regularization_lambda = 0.01\n",
    "    l1_regularization = regularization_lambda * tf.reduce_sum(tf.abs(weights))\n",
    "    l2_regularization = regularization_lambda * tf.reduce_sum(tf.square(weights))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y, predictions)\n",
    "        gradients = tape.gradient(loss, weights)\n",
    "\n",
    "    total_gradient = gradients + (l1_regularization if reg_type == \"l1\" else l2_regularization)\n",
    "    l1_weight = np.array(weights - total_gradient)\n",
    "    return magnitude_weight_selection(l1_weight, fraction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-10T16:47:42.460729Z"
    }
   },
   "id": "29ebbf1604008e33"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
